{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "######################################################################################\n",
    "# THis example is pretty much entirely based on this excellent blog post\n",
    "# http://glowingpython.blogspot.in/2014/09/text-summarization-with-nltk.html\n",
    "# Thanks to TheGlowingPython, the good soul that wrote this excellent article!\n",
    "# That blog is is really interesting btw.\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# nltk - \"natural language toolkit\" is a python library with support for \n",
    "#         natural language processing. Super-handy.\n",
    "# Specifically, we will use 2 functions from nltk\n",
    "#  sent_tokenize: given a group of text, tokenize (split) it into sentences\n",
    "#  word_tokenize: given a group of text, tokenize (split) it into words\n",
    "#  stopwords.words('english') to find and ignored very common words ('I', 'the',...) \n",
    "#  to use stopwords, you need to have run nltk.download() first - one-off setup\n",
    "######################################################################################\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "######################################################################################\n",
    "# We have use dictionaries so far, but now that we have covered classes - this is a good\n",
    "# time to introduce defaultdict. THis is class that inherits from dictionary, but has\n",
    "# one additional nice feature: Usually, a Python dictionary throws a KeyError if you try \n",
    "# to get an item with a key that is not currently in the dictionary. \n",
    "# The defaultdict in contrast will simply create any items that you try to access \n",
    "# (provided of course they do not exist yet). To create such a \"default\" item, it relies \n",
    "# a function that is passed in..more below. \n",
    "######################################################################################\n",
    "from collections import defaultdict\n",
    "\n",
    "######################################################################################\n",
    "#  punctuation to ignore punctuation symbols\n",
    "######################################################################################\n",
    "from string import punctuation\n",
    "\n",
    "######################################################################################\n",
    "# heapq.nlargest is a function that given a list, easily and quickly returns\n",
    "# the 'n' largest elements in the list. More below\n",
    "######################################################################################\n",
    "from heapq import nlargest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "######################################################################################\n",
    "# Our first class, named FrequencySummarizer \n",
    "######################################################################################\n",
    "class FrequencySummarizer:\n",
    "    # indentation changes - we are now inside the class definition\n",
    "    def __init__(self, min_cut=0.1, max_cut=0.9):\n",
    "        # The constructor named __init__\n",
    "        # THis function will be called each time an object of this class is instantiated\n",
    "        # btw, note how the special keyword 'self' is passed in as the first\n",
    "        # argument to each method (member function).\n",
    "        self._min_cut = min_cut\n",
    "        self._max_cut = max_cut \n",
    "        # Words that have a frequency term lower than min_cut \n",
    "        # or higer than max_cut will be ignored.\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "        # Punctuation symbols and stopwords (common words like 'an','the' etc) are ignored\n",
    "        #\n",
    "        # Here self._min_cut, self._max_cut and self._stopwords are all member variables\n",
    "        # i.e. each object (instance) of this class will have an independent version of these\n",
    "        # variables. \n",
    "        # Note how this function is used to set up the member variables to their appropriate values\n",
    "    # indentation changes - we are out of the constructor (member function, but we are still inside)\n",
    "    # the class.\n",
    "    # One important note: if you are used to programming in Java or C#: if you define a variable here\n",
    "    # i.e. outside a member function but inside the class - it becomes a STATIC member variable\n",
    "    # THis is an important difference from Java, C# (where all member variables would be defined here)\n",
    "    # and is a common gotcha to be avoided.\n",
    "\n",
    "    def _compute_frequencies(self, word_sent):\n",
    "        # next method (member function) which takes in self (the special keyword for this same object)\n",
    "        # as well as a list of sentences, and outputs a dictionary, where the keys are words, and\n",
    "        # values are the frequencies of those words in the set of sentences\n",
    "        freq = defaultdict(int)\n",
    "        # defaultdict, which we referred to above - is a class that inherits from dictionary,\n",
    "        # with one difference: Usually, a Python dictionary throws a KeyError if you try \n",
    "        # to get an item with a key that is not currently in the dictionary. \n",
    "        # The defaultdict in contrast will simply create any items that you try to access \n",
    "        # (provided of course they do not exist yet). THe 'int' passed in as argument tells\n",
    "        # the defaultdict object to create a default value of 0\n",
    "        for s in word_sent:\n",
    "        # indentation changes - we are inside the for loop, for each sentence\n",
    "          for word in s:\n",
    "            # indentation changes again - this is an inner for loop, once per each word_sent\n",
    "            # in that sentence\n",
    "            if word not in self._stopwords:\n",
    "                # if the word is in the member variable (dictionary) self._stopwords, then ignore it,\n",
    "                # else increment the frequency. Had the dictionary freq been a regular dictionary (not a \n",
    "                # defaultdict, we would have had to first check whether this word is in the dict\n",
    "                freq[word] += 1\n",
    "        # Done with the frequency calculation - now go through our frequency list and do 2 things\n",
    "        #   normalize the frequencies by dividing each by the highest frequency (this allows us to \n",
    "        #            always have frequencies between 0 and 1, which makes comparing them easy\n",
    "        #   filter out frequencies that are too high or too low. A trick that yields better results.\n",
    "        m = float(max(freq.values()))\n",
    "        # get the highest frequency of any word in the list of words\n",
    "        for w in freq.keys():\n",
    "            # indentation changes - we are inside the for loop\n",
    "            freq[w] = freq[w]/m\n",
    "            # divide each frequency by that max value, so it is now between 0 and 1\n",
    "            if freq[w] >= self._max_cut or freq[w] <= self._min_cut:\n",
    "                # indentation changes - we are inside the if statement - if we are here the word is either\n",
    "                # really common or really uncommon. In either case - delete it from our dictionary\n",
    "                del freq[w]\n",
    "                # remember that del can be used to remove a key-value pair from the dictionary\n",
    "        return freq\n",
    "        # return the frequency list\n",
    "\n",
    "    def summarize(self, text, n):\n",
    "        # next method (member function) which takes in self (the special keyword for this same object)\n",
    "        # as well as the raw text, and the number of sentences we wish the summary to contain. Return the \n",
    "        # summary\n",
    "        sents = sent_tokenize(text)\n",
    "        # split the text into sentences\n",
    "        assert n <= len(sents)\n",
    "        # assert is a way of making sure a condition holds true, else an exception is thrown. Used to do \n",
    "        # sanity checks like making sure the summary is shorter than the original article.\n",
    "        word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "        # This 1 sentence does a lot: it converts each sentence to lower-case, then \n",
    "        # splits each sentence into words, then takes all of those lists (1 per sentence)\n",
    "        # and mushes them into 1 big list\n",
    "        self._freq = self._compute_frequencies(word_sent)\n",
    "        # make a call to the method (member function) _compute_frequencies, and places that in\n",
    "        # the member variable _freq. \n",
    "        ranking = defaultdict(int)\n",
    "        # create an empty dictionary (of the superior defaultdict variety) to hold the rankings of the \n",
    "            # sentences. \n",
    "        for i,sent in enumerate(word_sent):\n",
    "            # Indentation changes - we are inside the for loop. Oh! and this is a different type of for loop\n",
    "            # A new built-in function, enumerate(), will make certain loops a bit clearer. enumerate(sequence), \n",
    "            # will return (0, thing[0]), (1, thing[1]), (2, thing[2]), and so forth.\n",
    "            # A common idiom to change every element of a list looks like this:\n",
    "            #  for i in range(len(L)):\n",
    "            #    item = L[i]\n",
    "            #    ... compute some result based on item ...\n",
    "            #    L[i] = result\n",
    "            # This can be rewritten using enumerate() as:\n",
    "            # for i, item in enumerate(L):\n",
    "            #    ... compute some result based on item ...\n",
    "            #    L[i] = result\n",
    "            for w in sent:\n",
    "                # for each word in this sentence\n",
    "                if w in self._freq:\n",
    "                    # if this is not a stopword (common word), add the frequency of that word \n",
    "                    # to the weightage assigned to that sentence \n",
    "                    ranking[i] += self._freq[w]\n",
    "        # OK - we are outside the for loop and now have rankings for all the sentences\n",
    "        print \"+++++++++++++++++++=========>\\n\",ranking,\"==>\\n\",ranking.get\n",
    "        sents_idx = nlargest(n, ranking, key=ranking.get)\n",
    "        # we want to return the first n sentences with highest ranking, use the nlargest function to do so\n",
    "        # this function needs to know how to get the list of values to rank, so give it a function - simply the \n",
    "        # get method of the dictionary\n",
    "        print \"***********\",sents_idx\n",
    "        return [sents[j] for j in sents_idx]\n",
    "       # return a list with these values in a list\n",
    "# Indentation changes - we are done with our FrequencySummarizer class!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_only_text_washington_post_url(url):\n",
    "    # This function takes in a URL as an argument, and returns only the text of the article in that URL. \n",
    "    print url\n",
    "    page = urllib2.urlopen(url).read().decode(encoding='UTF-8',errors='strict')\n",
    "    # download the URL\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    # initialise a BeautifulSoup object with the text of that URL\n",
    "    text = ' '.join(map(lambda p: p.text, soup.find_all('article')))\n",
    "    \n",
    "    # use this code to get everything in that text that lies between a pair of \n",
    "    # <article> and </article> tags. We do this because we know that the URLs we are currently\n",
    "    # interested in - those from the WashingtonPost have this nice property\n",
    "\n",
    "    # OK - we got everything between the <article> and </article> tags, but that everything\n",
    "    # includes a bunch of other stuff we don't want\n",
    "    # Now - repeat, but this time we will only take what lies between <p> and </p> tags\n",
    "    # these are HTML tags for \"paragraph\" i.e. this should give us the actual text of the article\n",
    "    soup2 = BeautifulSoup(text)\n",
    "    if soup2.find_all('p')!=[]:\n",
    "        text = ' '.join(map(lambda p: p.text, soup2.find_all('p')))\n",
    "    # use this code to get everything in that text that lies between a pair of \n",
    "    # <p> and </p> tags. We do this because we know that the URLs we are currently\n",
    "    # interested in - those from the WashingtonPost have this nice property\n",
    "    return soup.title.text, text\n",
    "# Return a pair of values (article title, article body)\n",
    "# Btw note that BeautifulSoup return the title without our doing anything special - \n",
    "# this is why BeautifulSoup works so much better than say regular expressions at parsing HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.biography.com/people/william-shakespeare-9480323\n",
      "+++++++++++++++++++=========>\n",
      "defaultdict(<type 'int'>, {0: 0.5833333333333334, 1: 9.950000000000005, 2: 0.11666666666666667, 3: 0.35, 4: 1.1666666666666667, 5: 0.5833333333333334, 6: 0.15, 7: 0.55, 8: 1.2666666666666666, 9: 1.7166666666666668, 10: 1.0166666666666666, 11: 0.5833333333333334, 12: 0.5833333333333334, 13: 1.3, 14: 0.9166666666666667, 15: 1.5, 16: 1.15, 17: 1.3, 18: 0.5833333333333334, 19: 0.11666666666666667, 20: 0.5833333333333334, 21: 0.13333333333333333, 22: 0.13333333333333333, 24: 1.65, 25: 0.7833333333333332, 28: 2.0, 29: 2.6166666666666667, 30: 0.8666666666666667, 31: 1.6500000000000001, 32: 1.1666666666666667, 33: 1.3166666666666667, 34: 0.21666666666666667, 36: 1.7833333333333337, 37: 0.5, 38: 0.5499999999999999, 39: 0.5833333333333334, 40: 0.11666666666666667, 41: 2.5833333333333335, 43: 0.35, 44: 2.416666666666667, 45: 0.7166666666666667, 46: 1.0833333333333335, 47: 2.183333333333333, 48: 0.7166666666666667, 49: 0.35, 50: 0.7166666666666667, 51: 1.55, 52: 0.7166666666666667, 53: 1.0333333333333332, 54: 0.33333333333333337, 56: 0.3666666666666667, 59: 3.2500000000000004, 60: 0.5, 61: 0.8666666666666667, 62: 0.9, 63: 0.8333333333333334, 64: 1.0666666666666667, 66: 0.5833333333333334, 67: 1.3, 68: 0.8333333333333334, 69: 0.5833333333333334, 70: 1.2000000000000002, 71: 0.18333333333333332, 72: 0.8333333333333334, 73: 1.7333333333333332, 74: 0.35, 75: 1.2833333333333334, 76: 3.85, 78: 1.1666666666666667, 80: 0.9666666666666667, 81: 0.11666666666666667, 82: 0.35, 83: 2.6166666666666667}) ==>\n",
      "<built-in method get of collections.defaultdict object at 0x000000000BD92160>\n",
      "*********** [1, 76, 59]\n",
      "[u'April 23, 1564Death DateApril 23, 1616EducationKing\\'s New SchoolPlace of BirthStratford-upon-Avon, United KingdomPlace of DeathStratford-upon-Avon, United KingdomAKAShakspereWill ShakespeareNickname\"Bard of Avon\"\"Swan of Avon\"\"The Bard\"Cite This PageWilliam Shakespeare, often called the English national poet, is widely considered the greatest dramatist of all time.IN THESE GROUPSFamous People Born in United KingdomFamous People Who Died in Stratford-upon-AvonFamous People in Fiction & PoetryFamous King\\'s New School AlumniShow All GroupsFamous People Named WilliamFamous PoetsFamous People Who Died in United KingdomFamous People Born in Stratford-upon-AvonFamous People Named ShakespeareFamous People Who Died in 1616Famous People Born in 1564Famous TaureansFamous PlaywrightsFamous People Born on April 23Famous People Who Died on April 23Famous British People{{ current.i + 1 }} of 17\\xab \\xbbquotes\\u201cThe fool doth think he is wise, but the wise man knows himself to be a fool.\\u201d\\u201cThis above all: to thine own self be true, and it must follow, as the night the day, thou canst not then be false to any man.\\u201d\\u201cThere is nothing either good or bad, but thinking makes it so.\\u201d\\u201cCowards die many times before their deaths; the valiant never taste of death but once.\\u201d\\u201cLord, what fools these mortals be!\\u201d\\u201cTo weep is to make less the depth of grief.\\u201d\\u201cIn time we hate that which we often fear.\\u201d\\u201cMen at some time are masters of their fates: the fault, dear Brutus, is not in our stars, but in ourselves, that we are underlings.\\u201d\\u201cWhat\\'s done cannot be undone.\\u201d\\u201cWe are such stuff as dreams are made on, and our little life is rounded with a sleep.\\u201d\\u201cMadness in great ones must not unwatched go.\\u201d\\u201cThe first thing we do, let\\'s kill all the lawyers.\\u201d\\u201cAll the world\\'s a stage, and all the men and women merely players.\\u201d\\u201cGive every man thy ear, but few thy voice.\\u201d\\u201cI say there is no darkness but ignorance.\\u201d\\u201cI wasted time, and now doth time waste me.\\u201d\\u201cSome are born great, some achieve greatness, and some have greatness thrust upon them.\\u201d\\x97William ShakespeareCloseSynopsisWilliam Shakespeare was baptized on April 26, 1564, in Stratford-upon-Avon, England.', u\"Royal records from 1601 show that William Shakespeare was recognized as a  member of the King's Men theater company (formerly\\xa0known as the  Chamberlain's Men) and a Groom of the Chamber by the court of King James  I, where the company performed seven of Shakespeare's plays.\", u'Other scholars note that the term \"second-best bed\"  often refers to the bed belonging to the household\\'s master and  mistres\\u2014the marital bed\\u2014and the \"first-best bed\" was reserved for  guests.Controversy and Literary LegacyAbout 150 years after his death, questions arose about the authorship  of William Shakespeare\\'s plays.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#####################################################################################\n",
    "# OK! Now lets give this code a spin\n",
    "#####################################################################################\n",
    "#someUrl = \"https://www.washingtonpost.com/news/the-switch/wp/2015/08/06/why-kids-are-meeting-more-strangers-online-than-ever-before/\"\n",
    "someUrl=\"http://www.biography.com/people/william-shakespeare-9480323\"\n",
    "# the article we would like to summarize\n",
    "textOfUrl = get_only_text_washington_post_url(someUrl)\n",
    "# get the title and text\n",
    "fs = FrequencySummarizer()\n",
    "# instantiate our FrequencySummarizer class and get an object of this class\n",
    "summary = fs.summarize(textOfUrl[1], 3)\n",
    "print summary\n",
    "# get a summary of this article that is 3 sentences long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'mistres\\u2014the marital bed\\u2014and'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ustring = u'mistres\\u2014the marital bed\\u2014and'\n",
    "ustring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistres\\xe2\\x80\\x94the marital bed\\xe2\\x80\\x94and'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ustring.encode('utf-8')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = ustring.encode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistres\\xe2\\x80\\x94the marital bed\\xe2\\x80\\x94and'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'mistres\\u2014the marital bed\\u2014and'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
